{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Fire in Sardinia 2025 - Part 2\"\n",
    "execute:\n",
    "  enabled: true\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "<a href='https://jupyterhub.user.eopf.eodc.eu/hub/login?next=/hub/spawn?next=/hub/user-redirect/git-pull?repo=https://github.com/eopf-toolkit/eopf-101&branch=main&urlpath=lab/tree/eopf-101/02_about_eopf_zarr/62_sardinia_s3_lst.ipynb#fancy-forms-config={\"profile\":\"choose-your-environment\",\"image\":\"unlisted_choice\",\"image:unlisted_choice\":\"4zm3809f.c1.de1.container-registry.ovh.net/eopf-toolkit-python/eopf-toolkit-python:latest\",\"autoStart\":\"true\"}' target=\"_blank\">\n",
    "  <button style=\"background-color:#0072ce; color:white; padding:0.6em 1.2em; font-size:1rem; border:none; border-radius:6px; margin-top:1em;\">\n",
    "    üöÄ Launch this notebook in JupyterLab\n",
    "  </button>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "**By:** *[@gisromerocandanedo](https://github.com/gisromerocandanedo)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Introduction\n",
    "\n",
    "On **June 10th, 2025**, a significant wildfire in Italy's Nuoro Province in Sardinia burned approximately 1000 hectares, a scale that is clearly visible in satellite imagery with a 20-meter resolution. [The European Forest Fire Information System (EFFIS)](https://forest-fire.emergency.copernicus.eu/apps/effis_current_situation/) keeps record of these events.\n",
    "\n",
    "This notebook demonstrates how two different `.zarr` encoded **Sentinel Mission products** can be combined to provide a compelling and informative overview of an active fire event.<br>\n",
    "\n",
    "First, we will use reflectance data from **Sentinel-2 L2A** to locate the area of the fire on the ground. At the same time, we will use data from **Sentinel-3 SLSTR Land Surface Temperature** (LST) to demonstrate the intense heat emanating from the fire.\n",
    "\n",
    "By combining these two datasets, we will not only be able to see the fire location and its state on the day of the event, but also understand its thermal intensity, providing a more complete perspective on its dynamics.\n",
    "\n",
    "This notebook is the second a series of three notebook:\n",
    "\n",
    "* [Part 1 - Compare Sentinel-2 True- and False-Color composites before and after a fire event](./61_sardinia_s2_tfci.ipynb)\n",
    "* **Part 2 - Analyse fire intensity with Sentinel-2 and -3 data**\n",
    "* [Part 3 - Assess burn severity with the normalised burn ratio (dNBR)](./63_sardinia_dNBR.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "###  What we will learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "- ‚úÇÔ∏è Extract and clip data from Sentinel-3 SLSTR L2 \n",
    "- üõ∞Ô∏è Visualise potential fires based on the relationship between Sentinel-2 and Sentinel-3 available items through the [EOPF STAC Catalog]()\n",
    "- üî≠ Demostrate the smooth multi-mission integration capabilities `.zarr` format offers to the community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import LocalCluster\n",
    "from pystac_client import Client\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Transformer\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from skimage import exposure\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "from shapely.geometry import box "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "This notebook makes use of a set of functions that are all listed inside the [zarr_wf_utils.py](./zarr_wf_utils.py) script. Inside the script, we will find costumised functions that allow us to mask, normalise and extract specific areas of our items of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our utility functions\n",
    "\n",
    "from zarr_wf_utils import (\n",
    "    validate_scl,\n",
    "    mask_sub_utm,\n",
    "    normalisation_str_gm,\n",
    "    mask_sub_latlon,\n",
    "    lat_lon_to_utm_box,\n",
    "    zarr_mask_latlon\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Initiate a Dask cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The first step is to initiate a **virtual Dask cluster**. This cluster consists of a scheduler (the \"brain\") and several workers (the \"hands\"), which enables faster processing of large datasets by breaking down tasks and running them in parallel.\n",
    "\n",
    "A client is then created to manage communication between the code and this cluster. For more information, feel free to visit the **dask** [documentation](https://docs.dask.org/en/stable/) and the tutorial [How to use dask](http://docs.dask.org/en/stable/#how-to-use-dask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are interested in the performance the code will have\n",
    "st = time.time()\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Establish a connection to the EOPF STAC Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Data is retrieved from the [EOPF STAC Catalogue](https://stac.browser.user.eopf.eodc.eu/?.language=en) endpoint. Once the connection is established, we can query the catalog based on specific search criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "eopf_stac_api_root_endpoint = \"https://stac.core.eopf.eodc.eu/\" #root starting point\n",
    "eopf_catalog = Client.open(url=eopf_stac_api_root_endpoint) # calls the selected url\n",
    "eopf_catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Define search paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The timeframe and area of interest for our filtering\n",
    "fire_d = '2025-06-11'\n",
    "fire_d_s3 = '2025-10-21'\n",
    "def_collection = ''\n",
    "\n",
    "search_bbox = (8.847198,40.193395,8.938865,40.241895)\n",
    "\n",
    "# Definition of the transformer parameters for reprojection and correct overlay of layers\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32632\", always_xy=True)\n",
    "t_utm_to_deg = Transformer.from_crs(\"EPSG:32632\",\"EPSG:4326\", always_xy=True)\n",
    "\n",
    "# Defining a larger bounding box for better visualisation:\n",
    "bbox_vis = (8.649555,40.073583,9.127893,40.343840)\n",
    "\n",
    "# A fixed geographic bounding box to highlight the AOI in the map format\n",
    "map_box = search_bbox\n",
    "\n",
    "# A new list with the converted UTM coordinates\n",
    "bbox_utm = lat_lon_to_utm_box((bbox_vis[0], bbox_vis[1]),(bbox_vis[2], bbox_vis[3]), transformer)\n",
    "\n",
    "# # Convert the coordinates of the map_box\n",
    "# map_box = lat_lon_to_utm_box((map_box[0], map_box[1]),(map_box[2], map_box[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Overview of processing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "In the following, we will go through three main processing steps:<br>\n",
    "\n",
    "* Step 1: Retrieving and visualising Land Surface Temperature from Sentinel-3 SLSTR L2 data\n",
    "* Step 2: Creating a True-Color composite of Sentinel-2 L2A data, and\n",
    "* Step 3: Overlaying both datasets, the True-Color composite with the Land Surface Temperature information "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Retrieve Land Surface Temperature (LST) from Sentinel-3 SLSTR L2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Land Surface Temperature (LST) data, can be retrieved from the Sentinel-3 SLSTR L2 collection. This data helps to identify temperature anomalies over the Earth's Surface, which can be a strong indicator of an active fire.\n",
    "\n",
    "In the following, we query the EOPF STAC Catalog to retrieve Land Surface Temperature from Sentinel-3 SLSTR L2 data.\n",
    "\n",
    "The search below introduces a new argument to the search: `query`. This argument allows us to go into the `.zarr` attributes metadata and filter based on specific parameters of the items we are interested in. We will filter for \"**Non-Time Critical**\" items.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the Sentinel-3 SLSTR L2 LST collection name\n",
    "def_collection = 'sentinel-3-slstr-l2-lst'\n",
    "\n",
    "# Search the catalog for items matching the criteria:\n",
    "s3_l2 = list(eopf_catalog.search(\n",
    "                bbox= search_bbox,  # A bounding box input to define the area of interest\n",
    "                datetime= fire_d_s3, # A datetime string input to specify the time range\n",
    "                collections=def_collection, # The collection name to search within\n",
    "                query = {\"product:timeliness_category\": {'eq':'NT'}} # A query to filter by timeliness category\n",
    "                                                                     # in the Catalog\n",
    "                ).item_collection())\n",
    "\n",
    "# Extract the URLs for the product assets from the search results\n",
    "av_urls = [item.assets[\"product\"].href for item in s3_l2]\n",
    "\n",
    "print(\"Search Results:\")\n",
    "print('Total Items Found for Sentinel-3 SLSRT over Sardinia:  ',len(av_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "After filtering the catalog, we open the **first** available Sentinel-3 SLSTR item, which corresponds to our specific timeframe of the selected day.\n",
    "\n",
    "For optimising the subsequent plotting, we can extract key information from the retrieved item, such as the date and the specific item time. Afterwards, we access the **Land Surface Temperature** (LST) asset. The LST data is available under the group `measurements`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the last item from the list of URLs as a Zarr data tree\n",
    "lst_zarr = xr.open_datatree(\n",
    "    av_urls[-1], # Input: URL of the last Zarr item in the av_urls list\n",
    "    engine=\"zarr\" # Specify the Zarr engine for opening the file\n",
    "    )\n",
    "\n",
    "# Extract the start date and time from the data tree's metadata\n",
    "date_zarr_lst = lst_zarr.attrs['stac_discovery']['properties']['start_datetime'][:10]\n",
    "time_zarr_lst = lst_zarr.attrs['stac_discovery']['properties']['start_datetime'][11:19]\n",
    "\n",
    "# Access the 'measurements' group within the data tree\n",
    "meas_lst = lst_zarr.measurements\n",
    "# The output is the measurements data group\n",
    "meas_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "To effectively overlay the data, we first need to process the Land Surface Temperature (LST) asset to cover the same area of interest.\n",
    "We can accomplish this by applying our pre-defined masking functions. Since the LST data is presented in **EPSG:4326**, we will use the `zarr_mask_latlon()` function to generate the boolean mask of interest over the data, followed by the `mask_sub_latlon()` function, which clips it to our area of interest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The zarr_mask_latlon function is used to create a mask based on a bounding box and the measurements data\n",
    "cols_lst , rows_lst = zarr_mask_latlon(\n",
    "    bbox_vis, # The input bounding box\n",
    "    meas_lst # The measurements group from the zarr data tree\n",
    "    )\n",
    "# The mask_sub_latlon function then clips the land surface temperature data\n",
    "lst_clip = mask_sub_latlon(\n",
    "    meas_lst.lst, # The land surface temperature band from the measurements group\n",
    "    rows_lst, # The row indices for the mask\n",
    "    cols_lst # The column indices for the mask\n",
    "    ).values\n",
    "\n",
    "# The latitude data is clipped using the same mask indices\n",
    "lat_lst = mask_sub_latlon(meas_lst['latitude'],rows_lst, cols_lst).values\n",
    "# The longitude data is clipped using the same mask indices\n",
    "lon_lst = mask_sub_latlon(meas_lst['longitude'],rows_lst, cols_lst).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "After clipping the data to our defined area of interest, we apply the **temperature threshold** to the data, filtering for only those pixels with **temperatures above 312 Kelvin**. This temperature range is a strong indicator of heat anomalies, which are often associated with active or developing fires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clip the data and prepare the array for an overlay with the TCI:\n",
    "lstf_clip = np.where(\n",
    "    lst_clip <= 312, # values less than or equal to 312 K\n",
    "    np.nan, # The value to assign if the condition is true\n",
    "    lst_clip # The value to assign if the condition is false\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "\n",
    "Creating a custom colour map that uses shades of red, with the most **vibrant red** indicating the **hottest** areas will enhance our visualisation. This colour map is applied to the LST data, allowing us to clearly and intuitively see the heat signatures that correspond with potential fire activity when the two layers are overlayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For colour ramp:\n",
    "col_map = ListedColormap([[1., 140./255., 0],[178./255., 34./255., 34./255.],[1, 0, 0]]) # red composite shades\n",
    "# Define the boundaries for each colour in the ramp\n",
    "bounds = [300, 305, 310, 315]\n",
    "# Calculate the number of colours, which is one less than the number of bounds\n",
    "ncolors = len(bounds) - 1\n",
    "# Create a normalisation object to map data values to colours based on the defined bounds\n",
    "norm = BoundaryNorm(bounds, col_map.N)\n",
    "\n",
    "# Use the box() function to create a polygon from the coordinates\n",
    "map_box = box(map_box[0],map_box[1],map_box[2],map_box[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "The final step of the Sentinel-3 SLSTR data processing is to **visualise** the temperature anomalies. We will prepare the filtered LST data to be overlaid over the True-Color composite of Sentinel-2 L2 data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a figure to plot\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(lst_clip)\n",
    "axs[0].set_title('Clipped LST')\n",
    "# Plot the filtered land surface temperature data on the second subplot\n",
    "axs[1].imshow(lstf_clip)\n",
    "axs[1].set_title('Filtered LST') # Add a title for clarity\n",
    "# Adjust the layout\n",
    "fig.tight_layout()\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### Create Sentinel-2 L2A True-Color composite\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Following the parameters we defined before and the workflow described in the [first part](./61_sardinia_s2_tfci.ipynb) of this notebook series, we will filter the **Sentinel-2 L2A** data collection to match our event and AOI. This ensures that the visualisations we create are directly relevant to the fire event and set the stage for comparing it with the Land Surface Temperature data from Sentinel-3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interest timeframe parameters for the filtering\n",
    "date_p = fire_d_s3 + 'T00:00:00Z/' + fire_d_s3 + 'T23:59:59.999999Z' # interest period\n",
    "def_collection = 'sentinel-2-l2a' # collection\n",
    "\n",
    "s2_col = list(eopf_catalog.search(\n",
    "                bbox= search_bbox, # area\n",
    "                datetime= date_p, #time frame\n",
    "                collections=def_collection # collection\n",
    "                ).item_collection())\n",
    "\n",
    "av_urls = [item.assets[\"product\"].href for item in s2_col]\n",
    "\n",
    "print(av_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "As we can see, there is no capture available for the day on which the fire occurred. This is because **Sentinel-2 L2A** has a **revisit time** of **five** days at the equator, making it possible that, even when the constellation is synchronously retrieving data, the day in question may not be available.<br>\n",
    "In this case, we define the capture date as the one closest to the event, the **11th June 2025**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interest timeframe parameters for the filtering\n",
    "date_p = fire_d + 'T00:00:00Z/' + fire_d + 'T23:59:59.999999Z' # interest period\n",
    "def_collection = 'sentinel-2-l2a' # collection\n",
    "s2_col = list(eopf_catalog.search(\n",
    "                bbox= search_bbox, # area\n",
    "                datetime= date_p, #time frame\n",
    "                collections=def_collection # collection\n",
    "                ).item_collection())\n",
    "\n",
    "av_urls = [item.assets[\"product\"].href for item in s2_col] \n",
    "av_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "Once we have obtained the available items from the **Sentinel-2 L2A** collection, we can open the asset as a xarray.DataTree.\n",
    "\n",
    "To prepare the data for further processing, we will extract key metadata like the collection, date, time, and the spectral bands needed for the visualisation (which are conveniently grouped under `r20m` group).\n",
    "\n",
    "These True-Color composite processing steps include:\n",
    "- Masking of invalid pixels\n",
    "- Clipping to AOI\n",
    "- Band selection\n",
    "- Normalisation\n",
    "- Composite creation\n",
    "- Equalisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "#### Masking out invalid pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are interested in the datasets contained in the measurements bands for True Colour and False Colour Composites.\n",
    "s2_zarr = xr.open_datatree(\n",
    "    av_urls[0], engine=\"zarr\", #we always get the earliest one (the first available item goes last)\n",
    "    chunks={},\n",
    "    decode_timedelta=False\n",
    "    )\n",
    "\n",
    "# Store interest parameters for further plotting:\n",
    "date = s2_zarr.attrs['stac_discovery']['properties']['start_datetime'][:10]\n",
    "time_zarr = s2_zarr.attrs['stac_discovery']['properties']['start_datetime'][11:19]\n",
    "# target_crs = s2_zarr.attrs[\"stac_discovery\"][\"properties\"][\"proj:epsg\"]\n",
    "# Extract the resolution group we are interested to analyse over:\n",
    "zarr_meas = s2_zarr.measurements.reflectance.r20m\n",
    "\n",
    "# Extract the cloud free mask at 20m resolution:\n",
    "l2a_class_20m = s2_zarr.conditions.mask.l2a_classification.r20m.scl\n",
    "valid_mask = validate_scl(l2a_class_20m)  # Boolean mask (10980x10980)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "#### Clipping to AOI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "In a next step, we clip the retrieved item to our defined area of interest (AOI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True colour channels we are interested to retrieve coposite:\n",
    "tc_red  = 'b04'\n",
    "tc_green= 'b03'\n",
    "tc_blue = 'b02'\n",
    "\n",
    "# Boolean mask for the 'x' dimension (longitude/easting)\n",
    "x_mask = (zarr_meas['x'] >= bbox_utm[0]) & (zarr_meas['x'] <= bbox_utm[2])\n",
    "# Boolean mask for the 'y' dimension (latitude/northing)\n",
    "y_mask = (zarr_meas['y'] >= bbox_utm[1]) & (zarr_meas['y'] <= bbox_utm[3])\n",
    "\n",
    "# Combined mask for the bounding box\n",
    "bbox_mask = x_mask & y_mask\n",
    "\n",
    "# Extract row and column indices where the mask is True\n",
    "cols, rows = np.where(bbox_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "#### Band selection, normalisation composite creation and equalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "In the next step, we proceed to select the relevant bands from the item, apply normalisation and equalisation, in order to visualise the True-Color composite of 11 June 2025 over the Nuoto region in Sardinia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tc_red, tc_green, and tc_blue variables are inputs specifying the band names\n",
    "red = zarr_meas[tc_red].where(valid_mask)\n",
    "gre =  zarr_meas[tc_green].where(valid_mask)\n",
    "blu =  zarr_meas[tc_blue].where(valid_mask)\n",
    "\n",
    "# The mask_sub_utm() function takes the bands and masks them to the valid rows and columns\n",
    "red = mask_sub_utm(red,rows, cols).values\n",
    "gre = mask_sub_utm(gre,rows, cols).values\n",
    "blu = mask_sub_utm(blu,rows, cols).values\n",
    "\n",
    "# The zarr_meas group is the input dataset containing the dimensions\n",
    "# by slicing the 'y' dimension array based on the minimum and maximum row indices\n",
    "y_zarr = zarr_meas['y'].isel(y=slice(rows.min(), rows.max() + 1)).values\n",
    "# also, the same for the 'x' dimension array based on the minimum and maximum column indices\n",
    "x_zarr = zarr_meas['x'].isel(x=slice(cols.min(), cols.max() + 1)).values\n",
    "\n",
    "map_ext_deg = list(t_utm_to_deg.transform(np.nanmin(x_zarr),np.nanmin(y_zarr)) + \n",
    "                   t_utm_to_deg.transform(np.nanmax(x_zarr),np.nanmax(y_zarr)))\n",
    "\n",
    "# Input: percentile range for contrast stretching\n",
    "contrast_stretch_percentile=(2, 98)\n",
    "# Input: gamma correction value\n",
    "gamma=1.8\n",
    "\n",
    "# Apply normalisation to the red, green and blue bands using the specified percentile and gamma values\n",
    "red_processed = normalisation_str_gm(red, *contrast_stretch_percentile, gamma)\n",
    "green_processed = normalisation_str_gm(gre, *contrast_stretch_percentile, gamma)\n",
    "blue_processed = normalisation_str_gm(blu, *contrast_stretch_percentile, gamma)\n",
    "\n",
    "# We stack the processed red, green, and blue arrays\n",
    "rgb_composite_sm = np.dstack((red_processed, green_processed, blue_processed)).astype(np.float32)\n",
    "\n",
    "#Adding equalisation from skimage:\n",
    "fire_tc = exposure.equalize_adapthist(rgb_composite_sm)\n",
    "\n",
    "\n",
    "plt.imshow(fire_tc)\n",
    "plt.title('Equalised Composite') # Add a title for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### Overlay Sentinel-2 True-Color composite with Sentinel-3 LST data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "And finally, we can **georeference** and overlay the two datasets, the True-Color composite from Sentinel-2 as well as the Land Surface Temperature information from Sentinel-3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overlay\n",
    "plt.figure(figsize=(14, 8))\n",
    "# Define the coordinate reference system (CRS) for latitude/longitude\n",
    "data_ll = ccrs.PlateCarree()\n",
    "\n",
    "ax = plt.axes(projection=data_ll)\n",
    "# Display the Sentinel-2 true-colour composite (TCI) image\n",
    "img = ax.imshow(fire_tc, origin='upper',\n",
    "                extent=[map_ext_deg[0],map_ext_deg[2],map_ext_deg[1],map_ext_deg[3]],  # item\n",
    "                transform=data_ll)\n",
    "# Display the land surface temperature (LST) data as an overlay\n",
    "im2 = ax.imshow(lstf_clip, origin='upper',\n",
    "                extent=[np.nanmin(lon_lst), np.nanmax(lon_lst),\n",
    "                        np.nanmin(lat_lst), np.nanmax(lat_lst)],\n",
    "                transform=data_ll, # coordinates\n",
    "                cmap=col_map,  norm=norm) # The custom colour map for LST\n",
    "cbar = plt.colorbar(im2,ticks=bounds, shrink=0.3)\n",
    "cbar.set_label(\"Land Surface Temperature (K)\")\n",
    "\n",
    "\n",
    "# features\n",
    "ax.add_geometries(map_box, crs=data_ll, facecolor='none', edgecolor='yellow', linewidth=2, linestyle='-')\n",
    "ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False) # Add gridlines and labels\n",
    "\n",
    "# Adjust title and plot parameters for a tight layout\n",
    "plt.title(f'Sentinel-2 L2A TCI + LST for the {fire_d_s3}', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "The **Sentinel-2 L2A** provides the geographical context of the landscape, while the **Sentinel-3 SLSTR** LST information provides an indication of the hottest areas on that day. This allows for a more accurate and immediate understanding of a fire's behaviour during the event. We can see that the hottest detected spot over the area of interest is indeed aligned with the fire event location.<br>\n",
    "\n",
    "The overlay provides additional information, especially in conditions where optical views are limited. For example, during less light hours or through heavy smoke, the thermal data can still reveal the fire's true footprint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "### Calculating processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "et = time.time()\n",
    "\n",
    "total_t = et - st\n",
    "\n",
    "print('Total Running Time: ', total_t,' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "A significant takeaway from this process is its remarkable speed. The entire workflow, from data access to visualisation, is completed in under two minutes. Here is the key evident advantage of using `.zarr` encoding for wildfire detection. <br>\n",
    "EOPF enables us to quickly access and combine Sentinel data directly from the cloud without the need to download large volumes of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "By integrating items from **Sentinel-2** with critical thermal data from **Sentinel-3** through the [EOPF STAC Catalog]() Collections, this notebook has demonstrated a complete and efficient workflow for analysing a real-world wildfire event. <br>\n",
    "\n",
    "We were able to create **a powerful overlay** that not only shows the **geographical context** of the **burnt area** but also precisely **identifies** the active **heat signatures** associated with the fire. This approach proves that combining different types of satellite data is essential for gaining a complete understanding of complex environmental events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## What‚Äôs next?\n",
    "\n",
    "Building on our visual analysis, the [next notebook](./63_sardinia_dNBR.ipynb) will introduce a quantitative method to assess fire severity. We will calculate the **Normalised Burn Ratio** (NBR) using data from **Sentinel-2** satellite imagery."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eopf_env_wf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
