{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Flood Mapping - Time Series Analysis in Valencia\" \n",
    "execute:\n",
    "  enabled: true\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "<a href=\"https://jupyterhub.user.eopf.eodc.eu/hub/login?next=%2Fhub%2Fspawn%3Fnext%3D%252Fhub%252Fuser-redirect%252Fgit-pull%253Frepo%253Dhttps%253A%252F%252Fgithub.com%252Feopf-toolkit%252Feopf-101%2526branch%253Dmain%2526urlpath%253Dlab%252Ftree%252Feopf-101%252F06_eopf_zarr_in_action%252F64_flood_mapping_valencia.ipynb%23fancy-forms-config=%7B%22profile%22%3A%22choose-your-environment%22%2C%22image%22%3A%22unlisted_choice%22%2C%22image%3Aunlisted_choice%22%3A%224zm3809f.c1.de1.container-registry.ovh.net%2Feopf-toolkit-python%2Feopf-toolkit-python%3Alatest%22%2C%22autoStart%22%3A%22true%22%7D\" target=\"_blank\">\n",
    "  <button style=\"background-color:#0072ce; color:white; padding:0.6em 1.2em; font-size:1rem; border:none; border-radius:6px; margin-top:1em;\">\n",
    "    üöÄ Launch this notebook in JupyterLab\n",
    "  </button>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "**By:** *[@beatrizbsperes](https://github.com/beatrizbsperes)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Sentinel-1 GRD** data is particularly valuable to detect water and underwater areas. Synthetic Aperture Radar (SAR) can capture images day and night, in any weather, a feature especially important for flooding events, where cloudy and rainy weather can persist for weeks. This makes it far more reliable than optical sensors during storms.\n",
    "\n",
    "With its frequent revisits, wide coverage, and free high-resolution data, **Sentinel-1** enables the rapid mapping of flood extents, as will be demonstrated in this workflow. **VV** polarization is preferred for flood mapping due to its sensitivity to water surfaces, which typically appear darker in the images compared to land surfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "#### The Flooding Event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "On October 29, 2024, the city of Valencia (Spain) was hit by catastrophic flooding caused by intense storms, leaving over 230 deaths and billions in damages. This disaster was part of Europe‚Äôs worst flood year in over a decade, with hundreds of thousands affected continent-wide. Such events highlight the urgent need for reliable flood monitoring to support **emergency response**, damage assessment and long-term resilience planning.\n",
    "\n",
    "With respect to this event, we will demonstrate how to use **Sentinel-1 GRD** data to map flood extents. We will use 14 **Sentinel-1 GRD** images from the **IW** swath, covering the city and metropolitan area of Valencia from October 7, 2024 to March 24, 2025. This includes 2 images captured before, 1 immediately after the heavy rains, and 11 images taken after the flooding event, until the water levels got back to normal:\n",
    "- October 7, 2424 (before)\n",
    "- October 19, 2024 (before)\n",
    "- October 31, 2024 (right after the event)\n",
    "- November 12, 2024 (after)\n",
    "- November 24, 2024 (after)\n",
    "- December 6, 2024 (after)\n",
    "- December 18, 2024 (after)\n",
    "- December 30, 2024 (after)\n",
    "- January 11, 2025 (after)\n",
    "- January 23, 2025 (after)\n",
    "- February 4, 2025 (after)\n",
    "- February 16, 2025 (after)\n",
    "- March 12, 2025 (after)\n",
    "- March 24, 2025 (after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### What we will learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "- üåä How to create a workflow to map flood events.\n",
    "- ‚öíÔ∏è Basic SAR processing tools.\n",
    "- üìä How to create a data cube to perform time series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "import xarray_sentinel \n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "import dask                             # these last two libraries are imported to open the datasets faster\n",
    "from dask.distributed import Client     # and in the end take advantage of the optimized .zarr format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "To search and load the data needed for the analysis, we will follow the processes we presented in [Sentinel-1 GRD structure tutorial](./../02_about_eopf_zarr/22_zarr_structure_S1GRD.ipynb) and [S1 basic operations tutorial](./../02_about_eopf_zarr/23_S1_basic_operations.ipynb).\n",
    "\n",
    "Once we defined our interest Sentinel-1 GRD items, we can see that they contain both **VH** and **VV** polarizations.<br>\n",
    "For this flood mapping context, **VV** polarization is the choice of interest, as water backscatter is much more visible with it, rather than with VH."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Loading the datatree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "The list below shows the names of the products we will use for the flood mapping and time series analysis.<br>\n",
    "As we have seen in previous chapters, these names already contain valuable information that can be used to search for specific products within the [EOPF STAC catalogue]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = [\"S1A_IW_GRDH_1SDV_20241007T180256_20241007T180321_056000_06D943_D46B\", \n",
    "          \"S1A_IW_GRDH_1SDV_20241019T180256_20241019T180321_056175_06E02E_2D52\", \n",
    "          \"S1A_IW_GRDH_1SDV_20241031T180256_20241031T180321_056350_06E71E_479F\", \n",
    "          \"S1A_IW_GRDH_1SDV_20241112T180255_20241112T180320_056525_06EE16_DC29\", \n",
    "          \"S1A_IW_GRDH_1SDV_20241124T180254_20241124T180319_056700_06F516_BA27\", \n",
    "          \"S1A_IW_GRDH_1SDV_20241206T180253_20241206T180318_056875_06FBFD_25AD\", \n",
    "          \"S1A_IW_GRDH_1SDV_20241218T180252_20241218T180317_057050_0702F2_0BC2\", \n",
    "          \"S1A_IW_GRDH_1SDV_20241230T180251_20241230T180316_057225_0709DD_15AC\", \n",
    "          \"S1A_IW_GRDH_1SDV_20250111T180250_20250111T180315_057400_0710C7_ADBB\", \n",
    "          \"S1A_IW_GRDH_1SDV_20250123T180249_20250123T180314_057575_0717B9_A784\", \n",
    "          \"S1A_IW_GRDH_1SDV_20250204T180249_20250204T180314_057750_071EA2_4373\", \n",
    "          \"S1A_IW_GRDH_1SDV_20250216T180248_20250216T180313_057925_0725AE_8AC7\", \n",
    "          \"S1A_IW_GRDH_1SDV_20250312T180248_20250312T180313_058275_0733E6_4F5B\", \n",
    "          \"S1A_IW_GRDH_1SDV_20250324T180248_20250324T180313_058450_073AD0_04B7\", \n",
    "          ]\n",
    "\n",
    "zarr_paths = []\n",
    "for scene in scenes:\n",
    "    zarr_paths.append(f\"https://objects.eodc.eu/e05ab01a9d56408d82ac32d69a5aae2a:notebook-data/tutorial_data/cpm_v260/{scene}.zarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Next, we will load all `zarr` datasets as xarray.Datatrees. Here **we are not reading** the entire dataset from the store; but, creating a set of references to the data, which enables us to access it efficiently later in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()  # Set up local cluster on your laptop\n",
    "client\n",
    "\n",
    "@dask.delayed\n",
    "def load_datatree_delayed(path):\n",
    "    return xr.open_datatree(path, consolidated=True, chunks=\"auto\")\n",
    "\n",
    "# Create delayed objects\n",
    "delayed_datatrees = [load_datatree_delayed(path) for path in zarr_paths]\n",
    "# Compute in parallel\n",
    "datatrees = dask.compute(*delayed_datatrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Each element inside the `datatree` list is a datatree and corresponds to a Sentinel-1 GRD scene datatree present on the list above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each element inside the datatree list is a datatree and corresponds to a Sentinel-1 GRD scene datatree present on the list above\n",
    "type(datatrees[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Defining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of scenes we are working with for the time series analysis\n",
    "DATASET_NUMBER = len(datatrees) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "If we run the following commented out code line we will be able to see how each datatree is organized within its groups and subgroups (as explained in this [section](./../02_about_eopf_zarr/22_zarr_structure_S1GRD.ipynb)). From this datatree, we took the groups and subgroups constant `ID` numbers used to open specific groups and variables such as:\n",
    "- Measurements group = 7 so, in order to open this group, on the first element of our list of scenes, over the first polarization `VV`, we do `datatrees[0][datatrees[0].groups[7]]`\n",
    "- GCP group = 28 so, in order to open this group, on the first element of our list of scenes, over the first polarization `VV`, we do `datatrees[0][datatrees[0].groups[28]]`\n",
    "- Calibration group = 33 so, in order to open this group, on the first element of our list of scenes, over the first polarization `VV`, we do `datatrees[0][datatrees[0].groups[33]]`\n",
    "\n",
    "Over the course of this notebook these `IDs` will be used to call variables and compute some other functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatrees[0].groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the measurements group from the datatree\n",
    "datatrees[0][datatrees[0].groups[7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other important constant ID numbers \n",
    "MEASUREMENTS_GROUP_ID = 7\n",
    "GCP_GROUP_ID = 28\n",
    "CALIBRATION_GROUP_ID = 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "We now define the thresholds that will be used for the flood mapping analysis. These values are not fixed and they can be calibrated and adjusted to achieve a better fit for different regions or flood events.<br>\n",
    "\n",
    "In SAR imagery, open water surfaces typically appear very dark because they reflect the radar signal away from the sensor. This results in low backscatter values. In our case, pixels with a backscatter lower than approximately ‚Äì15 dB are likely to correspond to water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "WATER_THRESHOLD_DB = -15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "It is interesting to study the flood event over a specific point within the area of interest.<br>\n",
    "Therefore, we are storing the coordinates of an anchor point inside the area which is not usually covered by water. After the heavy rain, it became flooded for a few weeks - this will be the point in which we study the evolution of the flood event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LAT = 39.28\n",
    "TARGET_LONG = -0.30\n",
    "\n",
    "# Define bounding box for Valencia area (min_lon, min_lat, max_lon, max_lat)\n",
    "bbox = [-0.45, 39.15, -0.15, 39.40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Extracting information from the `.zarr`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "As explained in the [S1 basic operations tutorial](23_S1_basic_operations.ipynb), we will perform over all the selected data the following operations:\n",
    "\n",
    "- Assigning latitude and longitude coordinates to the dataset\n",
    "- Computing the backscatter\n",
    "\n",
    "Also, we'll slice the data to meet our area of interest and decimate it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Slicing and decimating GRD variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "To begin with, we access all our `.zarr` items `measurements` groups by creating a list storing all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = []\n",
    "# Looping to populate the measurements list with only the measurements groups of each dataset on the datatree list\n",
    "for i in range(DATASET_NUMBER):\n",
    "    measurements.append(datatrees[i][datatrees[i].groups[MEASUREMENTS_GROUP_ID]].to_dataset())\n",
    "    # Execute it and store it in variable, instead of being lazy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "We continue by slicing `grd`'s data to focus on a specific area (Valencia). \n",
    "\n",
    "To properly slice the data for multiple products that will be combined into a time series, we need to use Ground Control Points (GCPs) to create a spatial mask based on latitude and longitude coordinates. This ensures that pixels across different acquisition dates correspond to the same ground locations. This is essential and speciallly necessary for accurate time series analysis since we'll need to stack the scenes on top of one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the first decimated GRD product from our list, corresponding to the whole scene\n",
    "measurements[0].grd.isel(\n",
    "        azimuth_time=slice(None, None, 20),\n",
    "        ground_range=slice(None, None, 20)).plot(vmax=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Azimuth time has\", measurements[0].grd.shape[0], \"values.\")\n",
    "print(\"Ground range has\", measurements[0].grd.shape[1], \"values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "We use GCPs to create a spatial mask based on our bounding box, then use that mask to find the corresponding slice in SAR geometry (azimuth_time and ground_range). This approach ensures that each pixel represents the same ground location across different products, which is crucial for time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd = []\n",
    "gcp = []\n",
    "\n",
    "# Looping to populate the grd list with GCP-based spatial slicing\n",
    "for i in range(DATASET_NUMBER):\n",
    "    # Load GCPs first\n",
    "    gcps = datatrees[i][datatrees[i].groups[GCP_GROUP_ID]].to_dataset()[[\"latitude\", \"longitude\"]]\n",
    "    \n",
    "    # Create spatial mask based on bounding box\n",
    "    mask = (\n",
    "        (gcps.latitude < bbox[3]) & (gcps.latitude > bbox[1]) &\n",
    "        (gcps.longitude < bbox[2]) & (gcps.longitude > bbox[0])\n",
    "    )\n",
    "    \n",
    "    # Find indices where mask is True\n",
    "    idx = np.where(mask == 1)\n",
    "    \n",
    "    if len(idx[0]) == 0 or len(idx[1]) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Build slice with offset to ensure we capture the full area\n",
    "    offset = 2\n",
    "    i0 = int(min(idx[0]))\n",
    "    i1 = int(max(idx[0]))\n",
    "    j0 = int(min(idx[1]))\n",
    "    j1 = int(max(idx[1]))\n",
    "    \n",
    "    azimuth_time_slice = slice(max(0, i0 - offset), min(mask.shape[0], i1 + offset + 1))\n",
    "    ground_range_slice = slice(max(0, j0 - offset), min(mask.shape[1], j1 + offset + 1))\n",
    "    \n",
    "    # Slice GCPs\n",
    "    gcps_crop = gcps.isel(\n",
    "        azimuth_time=azimuth_time_slice,\n",
    "        ground_range=ground_range_slice\n",
    "    )\n",
    "    \n",
    "    # Get min/max values from sliced GCPs for SAR geometry slicing\n",
    "    azimuth_time_min = gcps_crop.azimuth_time.min().values\n",
    "    azimuth_time_max = gcps_crop.azimuth_time.max().values\n",
    "    ground_range_min = gcps_crop.ground_range.min().values\n",
    "    ground_range_max = gcps_crop.ground_range.max().values\n",
    "    \n",
    "    # Slice GRD data using SAR geometry coordinates\n",
    "    grd_crop = measurements[i].grd.sel(\n",
    "        azimuth_time=slice(azimuth_time_min, azimuth_time_max),\n",
    "        ground_range=slice(ground_range_min, ground_range_max)\n",
    "    )\n",
    "    \n",
    "    # Decimate if needed (step=10 for faster processing)\n",
    "    grd_crop = grd_crop.isel(\n",
    "        azimuth_time=slice(None, None, 10),\n",
    "        ground_range=slice(None, None, 10)\n",
    "    )\n",
    "    \n",
    "    # Interpolate GCPs to match the sliced and decimated GRD\n",
    "    gcps_crop_interp = gcps_crop.interp_like(grd_crop)\n",
    "    \n",
    "    # Create final mask on interpolated coordinates\n",
    "    mask_2 = (\n",
    "        (gcps_crop_interp.latitude < bbox[3]) & (gcps_crop_interp.latitude > bbox[1]) &\n",
    "        (gcps_crop_interp.longitude < bbox[2]) & (gcps_crop_interp.longitude > bbox[0])\n",
    "    )\n",
    "    \n",
    "    # Apply mask and drop masked values\n",
    "    grd_crop = grd_crop.where(mask_2.compute(), drop=True)\n",
    "    \n",
    "    # We load all the variables already because we will use them in lots of future computations\n",
    "    grd.append(grd_crop.load())\n",
    "    gcp.append(gcps_crop_interp.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the first sliced and decimated GRD product from our list \n",
    "grd[0].plot(vmax=300)\n",
    "plt.title(\"Sliced GRD product for the area of interest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### Assigning latitude and longitude coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "We will execute the following step to assign latitude and longitude coordinates to our datasets:\n",
    "1. Creating a `gcp` dataset interpolated with the `grd` dataset;\n",
    "2. Assigning the latitude and longitude coordinates to the `grd` dataset;\n",
    "\n",
    "These steps are very important because we are computing a georeferenced image, which allows direct comparison with other spatial datasets. Until now, the image coordinates were expressed in `azimuth_time` and `ground_range`, which makes sense in a SAR context but not for geographical analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCPs are now loaded and interpolated during the slicing step above\n",
    "# Looping to assign the latitude and longitude coordinates to grd \n",
    "for i in range(DATASET_NUMBER):\n",
    "    grd[i] = grd[i].assign_coords({\"latitude\": gcp[i].latitude, \n",
    "                                   \"longitude\": gcp[i].longitude})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the third sliced and decimated GRD product from our list with latitude and longitude coordinates\n",
    "grd[0].plot(x=\"longitude\", y=\"latitude\", vmax=300)\n",
    "plt.title(\"GRD product with latitude and longitude coordinates\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### Computing backscatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "Again, the following steps are just recreating what was done before, but this time over more datasets. For further detailed information, take a look at this [chapter](./../02_about_eopf_zarr/23_S1_basic_operations.ipynb).\n",
    "\n",
    "Firstly we access the variables concerning the `calibration` values. These are the values that are going to be used for the backscatter computation. \n",
    "\n",
    "We use manual calibration with `sigma_nought` instead of `xarray_sentinel.calibrate_intensity()` because of known issues with the product format (see [forum discussion](https://forum.step.esa.int/t/constant-offset-for-grd-calibration/45194/9) and [GitLab issue](https://gitlab.eopf.copernicus.eu/cpm/eopf-cpm/-/issues/887#note_55104)). A function is created to make all the steps more automatic but you'll see that all the procedures done inside the `intensity_calibration` were already explained on the [previous tutorial](23_S1_basic_operations.ipynb). The manual approach uses `line` and `pixel` dimensions for interpolation, which correctly handles the calibration coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration = []\n",
    "# Looping to populate the calibration list with only the calibration groups of each dataset on the datatree list\n",
    "for i in range(DATASET_NUMBER):\n",
    "    calibration.append(datatrees[i][datatrees[i].groups[CALIBRATION_GROUP_ID]].to_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_calibration(calibration, grd):\n",
    "    \"\"\"\n",
    "    Computes the calibrated backscatter intensity from the GRD data and the calibration information.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    calibration : xarray.Dataset\n",
    "        Calibration data (e.g., sigma_nought).\n",
    "    grd : xarray.DataArray\n",
    "        GRD data to be calibrated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    calibrated_intensity : xarray.DataArray\n",
    "        Calibrated backscatter intensity in dB.\n",
    "    \"\"\"\n",
    "    # Accessing the sigma_nought values\n",
    "    sigma_nought = calibration.sigma_nought \n",
    "\n",
    "    # we reacreate the sigma_nought array with line and pixel dimensions for easier interpolation\n",
    "    sigma_nought_line_pixel = xr.DataArray(\n",
    "        data=sigma_nought.data,\n",
    "        dims=[\"line\", \"pixel\"],\n",
    "        coords=dict(\n",
    "            line=([\"line\"], sigma_nought.line.values),\n",
    "            pixel=([\"pixel\"], sigma_nought.pixel.values),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # just like for the sigma_nought, we reacreate the grd array with line and pixel dimensions for easier interpolation\n",
    "    grd_line_pixel = xr.DataArray(\n",
    "        data=grd.data,\n",
    "        dims=[\"line\", \"pixel\"],\n",
    "        coords=dict(\n",
    "            line=([\"line\"], grd.line.values),\n",
    "            pixel=([\"pixel\"], grd.pixel.values),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # we interpolate the sigma_nought with the grd geometry\n",
    "    sigma_nought_interp_line_pixel = sigma_nought_line_pixel.interp_like(grd_line_pixel, method=\"linear\")\n",
    "\n",
    "    sigma_nought_interp = xr.DataArray(\n",
    "        data=sigma_nought_interp_line_pixel.data,\n",
    "        dims=[\"azimuth_time\", \"ground_range\"],\n",
    "        coords=dict(\n",
    "            azimuth_time=([\"azimuth_time\"], grd.azimuth_time.values),\n",
    "            ground_range=([\"ground_range\"], grd.ground_range.values),\n",
    "        ),\n",
    "    )\n",
    "    intensity = 10 * np.log10(np.maximum(((abs(grd.astype(np.float32)) ** 2) / (sigma_nought_interp**2)), 1e-10))\n",
    "    return intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity = []\n",
    "# Looping to populate the calibration list with only the calibration groups of each dataset on the datatree list\n",
    "for i in range(DATASET_NUMBER):\n",
    "    intensity.append(intensity_calibration(calibration[i], grd[i]).load())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "In case we prefer to keep it more simple and calculate the intensity values with `xarray_sentinel` we can just uncomment the following cell and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intensity = []\n",
    "# # Looping to populate the intensity list with the calibrated intensity array originated from xarray_sentinel.calibrate_intensity function\n",
    "# for i in range(DATASET_NUMBER):\n",
    "#     intensity.append(xarray_sentinel.calibrate_intensity(\n",
    "#         grd[i], \n",
    "#         calibration[i].beta_nought, \n",
    "#         as_db=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the backscatter intensity for the first dataset on the list\n",
    "intensity[0].plot(x=\"longitude\", y=\"latitude\", vmin=-25, vmax=5)\n",
    "plt.title(\"Computed backscatter intensity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "### Create a datacube to prepare for time series analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "Since we are performing a time series with `.zarr`, instead of analysing individual items stored in a list, we can create a combined dataset, containing all the data, stacked together by a new dimension `time`. Through the stacking, we are building a three-dimensional datacube.\n",
    "\n",
    "To get values for the new dimension `time`, we need to extract the acquisiton dates for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "# Looping to populate the data list with all the acquisition dates from the datatree\n",
    "for i in range(len(intensity)):\n",
    "    data.append(intensity[i].azimuth_time.values[1].astype('datetime64[D]'))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "### Geocoding onto regular grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "In order to stack data into a time series datacube, we need to ensure that pixels across different acquisition dates correspond to the exact same ground locations. Since each Sentinel-1 GRD product has lat/lon coordinates on an irregular grid (due to SAR geometry), we need to geocode all products onto a common regular grid.\n",
    "\n",
    "This process involves:\n",
    "1. Creating a regular coordinate grid that covers all products\n",
    "2. Interpolating each product's backscatter values from its irregular lat/lon coordinates to the common regular grid\n",
    "3. Stacking the geocoded products into a time series datacube\n",
    "\n",
    "This ensures proper alignment for accurate time series analysis, where each pixel represents the same ground location across all dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regular_grid(min_x, max_x, min_y, max_y, spatialres):\n",
    "    \"\"\"\n",
    "    Create a regular coordinate grid given bounding box limits.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    min_x, max_x : float\n",
    "        Minimum and maximum X coordinates (e.g., longitude).\n",
    "    min_y, max_y : float\n",
    "        Minimum and maximum Y coordinates (e.g., latitude).\n",
    "    spatialres : float\n",
    "        Desired spatial resolution (in same units as x/y).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    grid_x_regular : ndarray\n",
    "        2D array of regularly spaced X coordinates.\n",
    "    grid_y_regular : ndarray\n",
    "        2D array of regularly spaced Y coordinates.\n",
    "    \"\"\"\n",
    "    # Ensure positive dimensions and consistent spacing\n",
    "    width = int(np.ceil((max_x - min_x) / spatialres))\n",
    "    height = int(np.ceil((max_y - min_y) / spatialres))\n",
    "    \n",
    "    # Compute grid centers (half-pixel offset)\n",
    "    half_pixel = spatialres / 2.0\n",
    "    x_regular = np.linspace(\n",
    "        min_x + half_pixel, max_x - half_pixel, width, dtype=np.float32\n",
    "    )\n",
    "    y_regular = np.linspace(\n",
    "        min_y + half_pixel, max_y - half_pixel, height, dtype=np.float32\n",
    "    )\n",
    "    \n",
    "    grid_x_regular, grid_y_regular = np.meshgrid(x_regular, y_regular)\n",
    "    return grid_x_regular, grid_y_regular\n",
    "\n",
    "\n",
    "def geocode_grd(sigma_0, grid_x_regular, grid_y_regular, time_val):\n",
    "    \"\"\"\n",
    "    Geocode GRD backscatter from irregular lat/lon grid to regular grid.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma_0 : xarray.DataArray\n",
    "        Backscatter intensity with latitude and longitude coordinates.\n",
    "    grid_x_regular : ndarray\n",
    "        2D array of regular X (longitude) coordinates.\n",
    "    grid_y_regular : ndarray\n",
    "        2D array of regular Y (latitude) coordinates.\n",
    "    time_val : datetime64\n",
    "        Time value for this product.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ds : xarray.Dataset\n",
    "        Geocoded dataset with regular x and y coordinates.\n",
    "    \"\"\"\n",
    "    grid_lat = sigma_0.latitude.values\n",
    "    grid_lon = sigma_0.longitude.values\n",
    "    \n",
    "    # Set border values to zero to avoid border artifacts with nearest interpolator\n",
    "    sigma_0_data = sigma_0.data.copy()\n",
    "    sigma_0_data[[0, -1], :] = 0\n",
    "    sigma_0_data[:, [0, -1]] = 0\n",
    "    \n",
    "    # Interpolate from irregular to regular grid\n",
    "    interpolated_values = griddata(\n",
    "        (grid_lon.flatten(), grid_lat.flatten()),\n",
    "        sigma_0_data.flatten(),\n",
    "        (grid_x_regular, grid_y_regular),\n",
    "        method=\"nearest\",\n",
    "    )\n",
    "    \n",
    "    # Create xarray Dataset with regular coordinates\n",
    "    ds = xr.Dataset(\n",
    "        coords=dict(\n",
    "            time=([\"time\"], [time_val]),\n",
    "            y=([\"y\"], grid_y_regular[:, 0]),\n",
    "            x=([\"x\"], grid_x_regular[0, :]),\n",
    "        )\n",
    "    )\n",
    "    ds[\"intensity\"] = ((\"time\", \"y\", \"x\"), np.expand_dims(interpolated_values, 0))\n",
    "    ds = ds.where(ds != 0)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "# Extract bounds from all intensity products to create common regular grid\n",
    "min_lat = min([i.latitude.min().values.item() for i in intensity])\n",
    "max_lat = max([i.latitude.max().values.item() for i in intensity])\n",
    "min_lon = min([i.longitude.min().values.item() for i in intensity])\n",
    "max_lon = max([i.longitude.max().values.item() for i in intensity])\n",
    "\n",
    "# Create common regular grid (resolution: 0.0001 degrees ‚âà 11 meters)\n",
    "grid_x_regular, grid_y_regular = create_regular_grid(\n",
    "    min_lon, max_lon, min_lat, max_lat, 0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "Now we geocode all products onto the common regular grid and stack them into a time series datacube. Each pixel now corresponds to the exact same ground location across all acquisition dates, enabling accurate time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geocode all products onto the common regular grid\n",
    "geocoded = []\n",
    "for i in range(len(intensity)):\n",
    "    geocoded.append(geocode_grd(intensity[i], grid_x_regular, grid_y_regular, data[i]))\n",
    "\n",
    "# Create the data cube by stacking all geocoded products\n",
    "intensity_data_cube = xr.concat(geocoded, dim=\"time\").sortby(\"time\")\n",
    "\n",
    "# There is a new dimension coordinate (time) \n",
    "intensity_data_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Flood mapping and time series analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "The last step is to perform the time series and flood mapping analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "### Simple visualisation of all datasets selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "First, we can plot all the datasets simply to create a visualisation of the flood. In addition to these plots, we are also plotting a chosen latitude and longitude point (as defined at beginning of this tutorial). The coordinate serves as a measure of comparison between all the datasets and from within different analysis methods.\n",
    "\n",
    "When we look over all the items plotted, we can clearly see that the significant flood event happened between the 19th and the 31st of October (it occurred on the 29th of October 2024).\n",
    "\n",
    "Additionally, we can see that the backscatter displaying the water presence was only going back to normal ranges around mid-February 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 4    # setting up column number\n",
    "rows = int(np.ceil(len(geocoded) / cols))  # setting up row number according to column number\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))  \n",
    "axes = axes.flatten()  \n",
    "\n",
    "for i in range(len(geocoded)):\n",
    "    ax = axes[i]\n",
    "    intensity_data_cube.isel(time=i).intensity.plot(    # plotting all the datasets stored in the data cube\n",
    "        x=\"x\", y=\"y\",\n",
    "        vmin=-25, vmax=5,\n",
    "        ax=ax,  \n",
    "        add_colorbar=False  \n",
    "    )\n",
    "    ax.scatter(TARGET_LONG, TARGET_LAT, color=\"red\", marker=\"o\", s=10, label=\"Selected Point\")  # also plotting the known point defined before\n",
    "    ax.legend(loc=\"upper right\")\n",
    "\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].axis('off')     # to avoid having empty cells\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "### Create a flood map based on threshold values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "It is known through [literature](https://www.researchgate.net/figure/VV-and-VH-threshold-statistics-1-obtained-via-graphical-interpretation-and-2_tbl4_360412209) and other [sources](https://mbonnema.github.io/GoogleEarthEngine/07-SAR-Water-Classification/?utm_source=chatgpt.com) that water appears as darker pixels, typically with values lower than **-15 dB**. This is a very good method for identifying water because separating the pixels within this threshold value will give us almost a `True` and `False` map for pixels which are greater or smaller than the defined threshold.\n",
    "\n",
    "In the plots below, we classify the pixels with backscatter values equal to or lower than -15 in yellow. Conversely, in purple, we see the pixels that have backscatter values greater than -15.\n",
    "\n",
    "This type of visualisation allows us to easily identify flooded and non-flooded areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))  \n",
    "axes = axes.flatten()  \n",
    "\n",
    "for i in range(len(geocoded)):\n",
    "    ax = axes[i]\n",
    "    water_mask = (intensity_data_cube.isel(time=i).intensity <= WATER_THRESHOLD_DB)     # defining the water mask from the threshold\n",
    "    water_mask.plot(        # plotting all the water masks \n",
    "        x=\"x\", y=\"y\",\n",
    "        ax=ax,  \n",
    "        add_colorbar=False  \n",
    "    )\n",
    "    ax.scatter(TARGET_LONG, TARGET_LAT, color=\"red\", marker=\"o\", s=10, label=\"Selected Point\") # again plotting the known point defined before\n",
    "    ax.legend(loc=\"upper right\")\n",
    "\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "### Create a map showing differences between two images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "Knowing the exact flood date, which we have, and from the images plotted previously, we can easily see that the second image is the one right before the flood event and that the third image is the one directly after it. These two images show significant differences in the flooded areas and backscatter values, ranging from **-5 dB** (in the image before the event) to **-20 dB** (in the image directly after the event).\n",
    "\n",
    "For this reason, when we compute the difference between the two images, we will mostly get:\n",
    "- Values around 0 dB for areas that did not change\n",
    "- Values ranging from -15 dB to -20 dB in the precise flooded areas.\n",
    "\n",
    "This is an excellent way to determine precisely which areas were flooded. As we are comparing an image from before the event with another one taken at the highest possible flooding point, the differences between them will be extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = (intensity_data_cube.isel(time=1).intensity - intensity_data_cube.isel(time=2).intensity)   # computing the difference between third and second dataset\n",
    "dif.plot(x=\"x\", y=\"y\", vmin=-10, vmax=20)\n",
    "plt.title(\"Flooded area right after the heavy rains\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "### Create a time-series plot of one location within the flood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "Taking advantage of the data cube we have created over a new `time` dimension, it is much easier to plot the data over this new dimension, as in a time series plot.<br>\n",
    "As our data now shares same dimensions and shape, we can choose to plot a backscatter analysis over the specific latitude and longitude point we defined earlier.<br>\n",
    "\n",
    "As these coordinates might not be exactly the ones shown on the dimension values, we need to perform some operations to find the closest values to the desired coordinates.<br> \n",
    "We will now change the latitude and longitude coordinate values and see how the corresponding `azimuth_time` and `ground_range` values and indexes change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how far each pixel's coordinates are from the target point\n",
    "abs_error = np.abs(intensity_data_cube.y - TARGET_LAT) + np.abs(intensity_data_cube.x - TARGET_LONG)  \n",
    "\n",
    "# Get the indexes of the closest point\n",
    "i, j = np.unravel_index(np.argmin(abs_error.values), abs_error.shape)\n",
    "y_index = i\n",
    "x_index = j\n",
    "\n",
    "# Get the coordinate values of the closest point\n",
    "y_value = intensity_data_cube.y[i].values\n",
    "x_value = intensity_data_cube.x[j].values\n",
    "\n",
    "print(\"Nearest y (latitude):\", y_value, \", with index:\", y_index)\n",
    "print(\"Nearest x (longitude):\", x_value, \", with index:\", x_index)\n",
    "\n",
    "# Slice the data cube in order to get only the pixel that corresponds to the target point\n",
    "target_point = intensity_data_cube.isel(y=y_index, x=x_index).intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "Now we can plot the data cube, showing the backscatter intensity over the target point we defined earlier. Since the datasets are stacked along the time dimension, it becomes much easier to plot the evolution of water backscatter at a specific location. This provides an effective way to monitor the flooding status at that point. \n",
    "\n",
    "We can also add a line representing the water threshold we defined. Any point with a backscatter value below this threshold will be classified as water, thus flooded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sliced data cube\n",
    "target_point.plot(label='Time series backscatter') \n",
    "\n",
    "x = target_point[target_point.dims[0]].values   # getting the x axis values (time)\n",
    "y = target_point.values                         # getting the y axis values (backscatter intensity)\n",
    "\n",
    "# Creating the trend line\n",
    "x_num = np.arange(len(x))   \n",
    "z = np.polyfit(x_num, y, 6)\n",
    "p = np.poly1d(z)\n",
    "\n",
    "plt.plot(x, p(x_num), 'r--', label='Trend line')\n",
    "plt.plot(x, [-15] * len(x), 'g--', label='Flood threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "## Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "While using the optimised `.zarr` format saves a lot of time and makes creating workflows relatively simple and achievable, there are still a few challenges to handle and to keep in mind:\n",
    "\n",
    "- Sentinel-1 GRD Data Availability: For **Sentinel-1 GRD**, most of the datasets are not yet available on the STAC catalogue. This makes searching and data handling harder because, in the end, only a few products are correctly converted.\n",
    "\n",
    "- Backscatter Computation: The `xarray_sentinel` library has known issues with certain product formats, requiring manual calibration using `sigma_nought` with `line` and `pixel` dimension interpolation. This tutorial demonstrates the correct manual calibration approach.\n",
    "\n",
    "- Geocoding: Proper geocoding onto a regular grid is essential for accurate time series analysis. This tutorial uses `scipy.interpolate.griddata` to geocode products from irregular SAR geometry coordinates to a common regular grid, ensuring pixels correspond to the same ground locations across all dates.\n",
    "\n",
    "- Terrain Correction: With the available libraries, it is very difficult to perform geometric and radiometric terrain correction. The existing tools that support the `.zarr` format are not yet fully operational and do not accept the format as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "The `.zarr` format is particularly well suited for hazard analysis because it enables multiple datasets to be combined into a single structure, either as a data cube or as a list of datatrees. This makes it ideal for rapid, multi-temporal, and multi-spatial monitoring. Unlike the `.SAFE` format, which required downloading entire products, `.zarr` only loads the specific groups needed, while the rest is accessed on the fly. As a result, both data handling and subsequent operations are much faster and more efficient. The `.load()` helps a lot on these situations.\n",
    "\n",
    "Although the ecosystem for `.zarr` is still evolving, there are already promising developments. In the past, `.SAFE` products could be fully processed on applications like SNAP, but similar completeness has not yet been reached for `.zarr`. Nevertheless, libraries such as `xarray_sentinel` and are beginning to cover essential SAR operations. This potential is illustrated in the Valencia flood case study, where Sentinel-1 backscatter sensitivity to water enabled clear mapping of flood extent and duration. The same workflow can be adapted to other flood events by adjusting the relevant thresholds and parameters to match local conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "## What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "In the following [notebook](./65_create_overviews.ipynb) we will explore a new approach to the **EOPF Zarr** format.<br>\n",
    "We will follow step by step the creation of **Overviews**, taking as a starting point the existing EOPF Zarr format structure and taking it to the next level!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eopf-101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
