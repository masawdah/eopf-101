{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Surface Water Dynamics - Time Series Analysis with Sentinel-1\"\n",
    "execute:\n",
    "  enabled: true\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Author\n",
    "\n",
    "- **Walid Ghariani** - [GitHub Profile](https://github.com/WalidGharianiEAGLE)\n",
    "\n",
    "### Affiliation\n",
    "- **DHI** - https://www.dhigroup.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Water is a vital part of Earth ecosystems and life, supporting biodiversity, and sustaining human livelihoods. Monitoring surface water dynamics (occurence, frequency and change) is important for managing resources, and mitigating natural hazards such as floods and droughts. Wetlands in particular are unique ecosystems under the influence of precipitaion, hydrological processes and coastal dynamics, which contribute in shaping the habitats, and species diversity. Within this context, the [Keta](https://rsis.ramsar.org/ris/567) and [Songor](https://rsis.ramsar.org/ris/566) [Ramsar](https://www.ramsar.org/) Sites in southeastern Ghana present a dynamic coastal wetland system where water levels fluctuate due to rainfall, tidal influence, and lagoon-river interactions. \n",
    "\n",
    "These ramsar sites consists of different wetlands classes such as marshes, floodplains, mangroves, and seasonally inundated grasslands. These unique sites are also critical habitats for thousands of resident and migratory birds, fish, and sea turtles, while supporting local livelihoods through fishing, agriculture, and salt production. Threfore an effective monitoring of water dynamics of these ecosystems is essential for conserving biodiversity and sustaining community resources.\n",
    "\n",
    "Sentinel-1 Synthetic Aperture Radar (SAR) can detect water under all weather conditions, overcoming limitations of optical imagery caused by cloud cover. By processing and analyzing Sentinel-1 time series and its radar backscatter (VH, VV), water occurrence, frequency and dynamics in Ramsar wetlands could be detected and monitored providing valuable insights of these complex wetlands sites.\n",
    "\n",
    "In this notebook, we will explore how to monitor surface water dynamics in coastal wetlands using Sentinel-1 time series. We will process radar backscatter data to detect water occurrence, frequency, and change over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### What we will learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "- üõ∞Ô∏è Accessing Sentinel-1 Ground Range Detected (GRD) `.zarr` data via the EODC STAC API using `pystac-client`.\n",
    "- üõ†Ô∏è Preprocessing radar imagery including spatial subsetting, radiometric calibration, speckle filtering, georeferencing, and regridding.\n",
    "- üåä Generating surface water masks using an adaptative thresholding algorithm.  \n",
    "- üìä Time series analysis of water dynamics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import fsspec\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pystac_client import Client\n",
    "\n",
    "import session_info\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pkg_resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Before starting the analysis workflow, we import several helper functions from **`zarr_s1_utils.py`** that implement key processing steps for Sentinel-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zarr_s1_utils import (\n",
    "    subset,\n",
    "    radiometric_calibration,\n",
    "    lee_filter_dask,\n",
    "    regrid,\n",
    "    xr_threshold_otsu,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_info.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Data search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "As we are interested into processing data that covers [Keta](https://rsis.ramsar.org/ris/567) and [Songor](https://rsis.ramsar.org/ris/566) [Ramsar](https://www.ramsar.org/) Sites in southeastern Ghana  we define our interest parameters for filering the Sentinel-1 GRD data using `pystac-client` in the EOPF STAC Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for the Area Of Interest (AOI), time range and Polarization\n",
    "aoi_bounds = [0.60912065235268, 5.759873096746288, 0.714565658530316, 5.837736228130655]\n",
    "date_start = dt.datetime(2024, 1, 1)\n",
    "date_end = dt.datetime(2025, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Client.open(\"https://stac.core.eopf.eodc.eu\")\n",
    "search = catalog.search(\n",
    "    collections=[\"sentinel-1-l1-grd\"],\n",
    "    bbox=aoi_bounds,\n",
    "    datetime=f\"{date_start:%Y-%m-%d}/{date_end:%Y-%m-%d}\",\n",
    ")\n",
    "items = search.item_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "To have an overview of the retrieved scenes, we can inspect the first item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets inspect the first item\n",
    "items[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "To have an overview of Sentinel-1's `.zarr` product, we can navigate its hierarchical structure, and extract the data, geolocation conditions, and calibration metadata for the polarization we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarization = \"VH\"  # or \"VV\"\n",
    "\n",
    "url = items[0].assets[\"product\"].href\n",
    "store = fsspec.get_mapper(url)\n",
    "datatree = xr.open_datatree(store, engine=\"zarr\", chunks={})\n",
    "group = [x for x in datatree.children if f\"{polarization}\" in x][0]\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd = datatree[group][\"measurements/grd\"]\n",
    "gcp = datatree[group][\"conditions/gcp\"].to_dataset()\n",
    "calibration = datatree[group][\"quality/calibration\"].to_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Spatial subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "To focus our analysis over the chosen AOI, we can efficiently crop our dataset using a spatial subset. The function **`subset()`** determine the slices in azimuth_time and ground_range that cover the AOI, and then extract and mask the corresponding portion of the GRD dataset.\n",
    "\n",
    "The function **`subset()`** takes the following keyword arguments:\n",
    "\n",
    "* **`grd`**:The GRD dataset to be cropped (the radar image in azimuth and ground range coordinates).\n",
    "* **`gcp_ds`**: The GCP (Ground Control Points) dataset containing the latitude and longitude grids used to geolocate the GRD image.\n",
    "* **`aoi_bounds`**: The geographic bounding box of the Area of Interest, given as: `[min_lon, min_lat, max_lon, max_lat]`.\n",
    "* **`offset`**: The number of GCP grid cells to include around the AOI center. This adds a small margin around the AOI to ensure the cropped region fully covers it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd_subset = subset(grd=grd, gcp_ds=gcp, aoi_bounds=aoi_bounds, offset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd_subset.plot(robust=True, cmap=\"cividis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Radiometric calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "In order to get a meanigful physical properties of features in the SAR scene that could be used for quantitative analysis, we need to apply a radiometric calibration on the backscatter values. This step converts the backscatter into a calibrated normalized radar cross section, correcting for incidence angle and sensor characteristics ensuring SAR images from different dates or viewing geometries are directly comparable. \n",
    "\n",
    "- Reference: https://step.esa.int/docs/tutorials/S1TBX%20SAR%20Basics%20Tutorial.pdf\n",
    "\n",
    "The radiometric calibration is done using the **`radiometric_calibration()`** function which takes the following keyword arguments:\n",
    "\n",
    "* **`grd`**:The GRD data array to be calibrated. \n",
    "* **`calibration_ds`**: The calibration dataset containing the radiometric calibration lookup tables provided with the product. This dataset is interpolated to the GRD grid before being applied.\n",
    "* **`calibration_type`**: The name of the calibration parameter to use from the calibration dataset. In this case, `sigma_nought` is used to compute the sigma nought backscatter coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "To have a look into the available data vars within the calibration dataset that could be used for the radiometric calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration.data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "We apply the calibration, obtaining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0 = radiometric_calibration(\n",
    "    grd=grd_subset, calibration_ds=calibration, calibration_type=\"sigma_nought\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0.plot(robust=True, cmap=\"cividis\", cbar_kwargs={\"label\": \"Sigma Nought\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### Speckel filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "Raw SAR imagery is characterized by \"grainy\" or \"salt and pepper\" effect caused by random constructive and destructive interference, known as **speckle**. In order to reduce this effect and noise, we apply the spatial **Lee Filter** ([Lee et al., 2009](https://doi.org/10.1080/02757259409532206)) that averages the pixel values while preserving edges.\n",
    "\n",
    "For speckel filtering we will use the **`lee_filter_dask()`** function which takes the following keyword arguments:\n",
    "\n",
    "* **`da`**: The input `xarray.DataArray` to be filtered. Here, `sigma_0` is the radiometrically calibrated GRD subset.\n",
    "* **`size`**: The size of the square moving window used to compute the local statistics for the Lee filter. Odd numbers are recommended (e.g., 5√ó5). Larger windows produce stronger smoothing but may reduce spatial detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk = lee_filter_dask(da=sigma_0, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "Obtaining a cleaner image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk.plot(robust=True, cmap=\"cividis\", cbar_kwargs={\"label\": \"Sigma Nought\"})\n",
    "plt.title(\"Sigma Nought after Lee Filter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### Georefrecing and regredding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "Sentinel-1 GRD Zarr comes in irregular image geometry that does not align with common geographic grids. In order to conduct spatial analysis, and scenes comparison, and mapping, we need to georefrence and resample the data onto a regular grid.<br>\n",
    "We will use an [ODC GeoBox](https://odc-geo.readthedocs.io/en/latest/intro-geobox.html) along with with [scipy.griddata](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.griddata.html) to interpolate the SAR values onto a consistent latitude-longitude grid. These utilities are available within the **`regrid()`** function which takes the following keyword arguments:\n",
    "\n",
    "* **`da`**: The input `xarray.DataArray` to regrid. Here, `sigma_0_spk` is the speckle-filtered GRD subset.\n",
    "* **`bounds`**: The geographic bounding box for the output grid: `[min_lon, min_lat, max_lon, max_lat]`.\n",
    "* **`resolution`**: Tuple `(dx, dy)` defining the grid spacing in the coordinate units of the CRS. For example, `10 / 111320` degrees corresponds roughly to 10 meters.\n",
    "* **`crs`**: Coordinate reference system of the output grid (default is `\"EPSG:4326\"` for WGS84).\n",
    "* **`method`**: Interpolation method for mapping irregularly spaced data to the regular grid. Options include `\"nearest\"`, `\"linear\"`, or `\"cubic\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 10 / 111320  # approx 10 meters in degrees\n",
    "crs = \"epsg:4326\"\n",
    "\n",
    "sigma_0_spk_geo = regrid(\n",
    "    da=sigma_0_spk,\n",
    "    bounds=aoi_bounds,\n",
    "    resolution=resolution,\n",
    "    crs=crs,\n",
    "    method=\"nearest\",  # \"linear\" or \"cubic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk_geo.odcgeobox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk_geo.plot(robust=True, cmap=\"cividis\", cbar_kwargs={\"label\": \"Sigma Nought\"})\n",
    "plt.title(\"Regridded Sigma Nought after Lee Filter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "### Convert backscatter to dB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "We convert the regridded `sigma_0` backscatter intensity from Linear scale to decibels (dB) using a logarithmic transformation. This enhances contrast and simplifies statistical analysis and interpretation of the image. It is considered a standard approach for representing SAR intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk_geo_db = 10 * np.log10(sigma_0_spk_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk_geo_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk_geo_db.plot(\n",
    "    robust=True, cmap=\"cividis\", cbar_kwargs={\"label\": \"Sigma Nought dB\"}\n",
    ")\n",
    "plt.title(\"Calibrated Sigma Nought in dB\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk_geo_db.hvplot.image(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    robust=True,\n",
    "    cmap=\"cividis\",\n",
    "    title=\"SAR GRD\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "## Water mask "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "To separate water from non-water surfaces, we first inspect the distribution of backscatter values using a histogram. In the following histogram we could choose -19 as therhold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sigma_0_spk_geo_db.values.ravel(), bins=50, alpha=0.7)\n",
    "plt.title(\"Histogram of Sigma Nought (dB) Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "Since SAR water thresholds vary across scenes and times, a fixed cutoff is unreliable. Threfore, we apply an adaptative thresholding method using **Otsu** algorithm provided by [skimage](https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.threshold_otsu), which automatically determines an optimal threshold from the intensity distribution and create a water mask accordingly. This algorithm is available within **`xr_threshold_otsu`** function which takes the following keyword arguments:\n",
    "\n",
    "* **`da`**: Input `xarray.DataArray` to threshold. \n",
    "* **`mask_nan`**: If True (default), any NaN values are ignored during threshold computation.\n",
    "* **`return_threshold`**: If True, the calculated threshold value is stored as an attribute of the resulting mask.\n",
    "* **`mask_name`**: Optional name for the binary mask DataArray. This helps with metadata or when saving to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_mask = xr_threshold_otsu(\n",
    "    da=sigma_0_spk_geo_db, mask_nan=True, return_threshold=True, mask_name=\"water_mask\"\n",
    ")\n",
    "print(f\"Otsu threshold: {water_mask.attrs['threshold']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 - water_mask).plot(cmap=\"Blues\")\n",
    "plt.title(\"Water Mask (1 = Water, 0 = Non-Water)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 - water_mask).hvplot.image(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    cmap=\"Blues\",\n",
    "    robust=True,\n",
    "    title=\"Water Mask\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "## Time series analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "So far we have walked through each processing step separately. To automate the workflow and apply it efficiently across Sentinel-1 acquisitions, we could now wrap all these operations into a single processing function **`process_item`**. This allows us to automatically generate water masks for every item in our STAC collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_item(\n",
    "    item, aoi_bounds, polarization=\"VH\", resolution=10 / 111320, crs=\"epsg:4326\"\n",
    "):\n",
    "    \"\"\"Process a STAC item to generate water mask and timestamp.\"\"\"\n",
    "    url = item.assets[\"product\"].href\n",
    "    store = fsspec.get_mapper(url)\n",
    "    datatree = xr.open_datatree(store, engine=\"zarr\", chunks={})\n",
    "\n",
    "    group_VH = [x for x in datatree.children if f\"{polarization}\" in x][0]\n",
    "\n",
    "    grd = datatree[group_VH][\"measurements/grd\"]\n",
    "    gcp = datatree[group_VH][\"conditions/gcp\"].to_dataset()\n",
    "    calibration = datatree[group_VH][\"quality/calibration\"].to_dataset()\n",
    "\n",
    "    grd_subset = subset(grd, gcp, aoi_bounds, offset=1)\n",
    "    sigma_0 = radiometric_calibration(\n",
    "        grd_subset, calibration, calibration_type=\"sigma_nought\"\n",
    "    )\n",
    "    sigma_0_spk = lee_filter_dask(sigma_0, size=5)\n",
    "    sigma_0_spk_geo = regrid(\n",
    "        da=sigma_0_spk,\n",
    "        bounds=aoi_bounds,\n",
    "        resolution=resolution,\n",
    "        crs=crs,\n",
    "        method=\"nearest\",\n",
    "    )\n",
    "    sigma_0_spk_geo_db = 10 * np.log10(sigma_0_spk_geo)\n",
    "    water_mask = xr_threshold_otsu(\n",
    "        sigma_0_spk_geo_db, return_threshold=True, mask_name=\"water_mask\"\n",
    "    )\n",
    "\n",
    "    t = np.datetime64(item.properties[\"datetime\"][:-2], \"ns\")\n",
    "    water_mask = water_mask.assign_coords(time=t)\n",
    "\n",
    "    return water_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "Now we loop through all STAC items and use the `process_item` to build the full water-mask dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_masks = []\n",
    "thresholds = []\n",
    "\n",
    "for item in tqdm(items):\n",
    "    water_mask = process_item(item, aoi_bounds)\n",
    "    water_masks.append(1 - water_mask)  # invert mask to have 1 = water\n",
    "    thresholds.append(water_mask.attrs[\"threshold\"])\n",
    "\n",
    "water_mask_ds = xr.concat(water_masks, dim=\"time\")\n",
    "water_mask_ds = water_mask_ds.assign_coords(threshold=(\"time\", thresholds)).sortby(\n",
    "    \"time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_mask_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the water mask thresholds over time\n",
    "plt.plot(water_mask_ds.time, water_mask_ds.threshold, marker=\"o\")\n",
    "plt.title(\"Water Mask Thresholds over Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = water_mask_ds.time\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "Lets inspect the water mask for the first 4 dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_mask_ds.sel(time=dates[:4]).plot(col=\"time\", cmap=\"Blues\", vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "We found out that the RAW Sentinel-1 GRD scene for 2024-06-07 has issues and artificat that will lead to incorrect water classification. Therefore, we will exclude it from our water frequency analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_date = pd.to_datetime(\"2024-06-07\").date()\n",
    "filtered_water_ds = water_mask_ds.sel(\n",
    "    time=water_mask_ds.time.to_index().date != bad_date\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_water_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "### Monthly surface water frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "Now that we have the water masks, we can group them by month, compute the average water presence for each pixel, and convert it to a percentage (%) to represent monthly water frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_water_frequency = filtered_water_ds.groupby(\"time.month\").mean(\"time\") * 100\n",
    "\n",
    "monthly_water_frequency.name = \"SWF\"\n",
    "month_names = pd.date_range(start=\"2024-01-01\", periods=12, freq=\"ME\").strftime(\"%B\")\n",
    "monthly_water_frequency.coords[\"month\"] = (\"month\", month_names)\n",
    "monthly_water_frequency = monthly_water_frequency.assign_attrs(\n",
    "    long_name=\"Surface Water Frequency\"\n",
    ")\n",
    "monthly_water_frequency = monthly_water_frequency.assign_attrs(units=\"%\")\n",
    "monthly_water_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_water_frequency.plot(col=\"month\", col_wrap=4, cmap=\"Blues\", robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "### Annual surface water frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "Lets calculates the average water occurence across the entire time series over the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_water_frequency = filtered_water_ds.mean(\"time\") * 100\n",
    "annual_water_frequency = annual_water_frequency.assign_attrs(\n",
    "    long_name=\"Surface Water Frequency\"\n",
    ")\n",
    "annual_water_frequency = annual_water_frequency.assign_attrs(units=\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_water_frequency.plot(cmap=\"Blues\")\n",
    "plt.title(\"Annual Surface Water Frequency (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_water_frequency.hvplot.image(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    robust=True,\n",
    "    cmap=\"Blues\",\n",
    "    title=\"Annual Surface Water Frequency (%)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "### Annual water change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "We could also computes the standard deviation of water presence over time. This highlights areas with high water variability (seasonal or dynamic water bodies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_water_change = filtered_water_ds.std(\"time\") * 100\n",
    "annual_water_change = annual_water_change.assign_attrs(\n",
    "    long_name=\"Surface Water Variation\"\n",
    ")\n",
    "annual_water_change = annual_water_change.assign_attrs(units=\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_water_change.plot(cmap=\"magma\")\n",
    "plt.title(\"Annual Surface Water Variation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_water_change.hvplot.image(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    robust=True,\n",
    "    cmap=\"magma\",\n",
    "    title=\"Annual Surface Water Variation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "## üí™ Now it is your turn \n",
    "\n",
    "congratulations üéâ<br>\n",
    "\n",
    "We have worked through the complete workflow for analyzing Sentinel-1 surface water dynamics from `.zarr` data. Now it is your turn to explore and expand the analysis in the following ways:\n",
    "\n",
    "### Task 1: Explore your own area of interest\n",
    "\n",
    "Choose a different wetland, lake system, river delta, or floodplain anywhere in the world. Use different STAC search configurations (`aoi_bounds`, `date_start`, `date_end`) and derive the:\n",
    "\n",
    "* Seasonal variation\n",
    "* Maximum water extent\n",
    "* Minumum water extent\n",
    "* Long-term changes in water extent (more than 1 year of data)\n",
    "\n",
    "###  Task 2: Experiment with other polarizations and combinations\n",
    "\n",
    "Instead of relying solely on `VH` for water extraction try:\n",
    "\n",
    "* `VV` polarization\n",
    "* `VH/VV` ratio\n",
    "* Dual-polarization thresholding or machine learning classification ([Kreiser, Z. et al., 2018](https://doi.org/10.1109/IGARSS.2018.8517447))\n",
    "\n",
    "### Task 3: Compare or integrate Sentinel-1 with Sentinel-2\n",
    "\n",
    "* Design a workflow for Sentinel-2 water detection and consider using spectral indices such as the Normalized Difference Water Index (NDWI) [Gao, 1996](https://doi.org/10.1016/S0034-4257(96)00067-3) or the Modified Normalized Difference Water Index (mNDWI) [Xu, 2006](https://doi.org/10.1080/01431160600589179).\n",
    "\n",
    "* Compare Sentinel-2 water dectection with our Sentinel-1 workflow. \n",
    "* Recent studies show that combining Sentinel-1 and Sentinel-2 data can improve water detection ([Bioresita et al., 2019](https://doi.org/10.1080/01431161.2019.1624869); [Kaplan and Avdan 2018](https://doi.org/10.5194/isprs-archives-XLII-3-729-2018)). Consider exploring methods that fuse the information from both sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrated how to use Sentinel-1 data in `.zarr` format for time-series analysis of surface water dynamics in a wetland coastal and cloudy-prone area. The zarr structure is especially useful for efficient extraction of data over a specific area of interest without loading the full dataset.\n",
    "\n",
    "We developed a streamlined time series workflow using `pystac-client` and the EODC STAC API to preprocess Sentinel-1 GRD data. This included spatial subsetting, radiometric calibration, speckle filtering, georeferencing, and regridding. We also implemented an automated process for surface water detection and derived surface water occurrence, frequency, and change.\n",
    "\n",
    "**Note**: Although in this notebook we opted to use `VH` polarization to detect the water, users may also experiment with `VV` polarization or combine both polarizations for improved water detection, and implement their own methods for deriving surface water masks. This workflow can also be adapted for other applications, such as monitoring lake dynamic and flood events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "This resource is constantly updated!. Stay Tuned for new chapters üõ∞Ô∏è !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
